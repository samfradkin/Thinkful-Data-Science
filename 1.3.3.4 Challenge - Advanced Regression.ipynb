{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.3.4 Challenge - Advanced Regression\n",
    "### Sam Fradkin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "_Now that you have two new regression methods at your fingertips, it's time to give them a spin. In fact, for this challenge, let's put them together! Pick a dataset of your choice with a binary outcome and the potential for at least 15 features. If you're drawing a blank, the crime rates in 2013 dataset has a lot of variables that could be made into a modelable binary outcome._\n",
    "\n",
    "_Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:_\n",
    "\n",
    "_1) Vanilla logistic regression_<br>\n",
    "_2) Ridge logistic regression_<br>\n",
    "_3) Lasso logistic regression_<br>\n",
    "\n",
    "_If you're stuck on how to begin combining your two new modeling skills, here's a hint: the SKlearn LogisticRegression method has a \"penalty\" argument that takes either 'l1' or 'l2' as a value._\n",
    "\n",
    "_In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?_\n",
    "\n",
    "_Record your work and reflections in a notebook to discuss with your mentor._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso, Ridge\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Female</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>EmbC</th>\n",
       "      <th>EmbQ</th>\n",
       "      <th>EmbS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Age  Female  SibSp  Parch  Class   Fare  EmbC  EmbQ  EmbS\n",
       "0         1    1       0      0      1      3   8.52     1     0     0\n",
       "1         1    1       0      1      1      2  14.50     0     0     1\n",
       "2         1    1       1      2      1      3  19.26     1     0     0\n",
       "3         1    1       1      2      1      3  19.26     1     0     0\n",
       "4         1    1       0      0      2      2  29.00     0     0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Titanic Train Clean.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 714 entries, 0 to 713\n",
      "Data columns (total 10 columns):\n",
      "Survived    714 non-null int64\n",
      "Age         714 non-null int64\n",
      "Female      714 non-null int64\n",
      "SibSp       714 non-null int64\n",
      "Parch       714 non-null int64\n",
      "Class       714 non-null int64\n",
      "Fare        714 non-null float64\n",
      "EmbC        714 non-null int64\n",
      "EmbQ        714 non-null int64\n",
      "EmbS        714 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 55.9 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Female</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>EmbC</th>\n",
       "      <th>EmbQ</th>\n",
       "      <th>EmbS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.406162</td>\n",
       "      <td>29.714286</td>\n",
       "      <td>0.365546</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>2.236695</td>\n",
       "      <td>34.695294</td>\n",
       "      <td>0.182073</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.778711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491460</td>\n",
       "      <td>14.526453</td>\n",
       "      <td>0.481921</td>\n",
       "      <td>0.929783</td>\n",
       "      <td>0.853289</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>52.918912</td>\n",
       "      <td>0.386175</td>\n",
       "      <td>0.194244</td>\n",
       "      <td>0.415405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>512.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived         Age      Female       SibSp       Parch       Class  \\\n",
       "count  714.000000  714.000000  714.000000  714.000000  714.000000  714.000000   \n",
       "mean     0.406162   29.714286    0.365546    0.512605    0.431373    2.236695   \n",
       "std      0.491460   14.526453    0.481921    0.929783    0.853289    0.838250   \n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "25%      0.000000   20.250000    0.000000    0.000000    0.000000    1.000000   \n",
       "50%      0.000000   28.000000    0.000000    0.000000    0.000000    2.000000   \n",
       "75%      1.000000   38.000000    1.000000    1.000000    1.000000    3.000000   \n",
       "max      1.000000   80.000000    1.000000    5.000000    6.000000    3.000000   \n",
       "\n",
       "             Fare        EmbC        EmbQ        EmbS  \n",
       "count  714.000000  714.000000  714.000000  714.000000  \n",
       "mean    34.695294    0.182073    0.039216    0.778711  \n",
       "std     52.918912    0.386175    0.194244    0.415405  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      8.050000    0.000000    0.000000    1.000000  \n",
       "50%     15.740000    0.000000    0.000000    1.000000  \n",
       "75%     33.375000    0.000000    0.000000    1.000000  \n",
       "max    512.330000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot some of the data to get a sense of the picture it paints\n",
    "\n",
    "f, axes = plt.subplots(1, 2, sharey = True, figsize=(14,6))\n",
    "sns.countplot(x = 'Survived', hue = 'Female', palette = 'RdBu_r', data = train, ax = axes[0])\n",
    "sns.countplot(x = 'Survived', hue = 'Class', data = train, ax = axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with our modeling process by splitting the dataframe into our features and our target feature\n",
    "X = train.drop('Survived', axis = 1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some crossvalidation on our dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A) Vanilla Logistic Regression Model (Dataset as is)\n",
    "\n",
    "Let's run the vanilla model before we engineer added features just to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Vanilla Logistic Regression on the dataset and see what results we get\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- RESULTS ----------\n",
      "\n",
      "--- R-SQUARED ---\n",
      "0.8177966101694916\n",
      "\n",
      "--- CONFUSION MATRIX ---\n",
      "[[119  24]\n",
      " [ 19  74]]\n",
      "\n",
      "--- PERFORMANCE ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       143\n",
      "           1       0.76      0.80      0.77        93\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       236\n",
      "   macro avg       0.81      0.81      0.81       236\n",
      "weighted avg       0.82      0.82      0.82       236\n",
      "\n",
      "\n",
      "--- INTERCEPTS ---\n",
      "[[-3.49547657e-02  2.41077997e+00 -2.33371287e-01 -4.94697975e-02\n",
      "  -1.05427257e+00  2.36193042e-03  1.02421604e+00  5.17612913e-02\n",
      "   4.90668826e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('---------- RESULTS ----------')\n",
    "print()\n",
    "print('--- R-SQUARED ---')\n",
    "print(logreg.score(X_test, y_test))\n",
    "print('\\n--- CONFUSION MATRIX ---')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n--- PERFORMANCE ---')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n--- INTERCEPTS ---')\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it performs quite well as is! Let's add more features, run it again, and try Ridge and Lasso as well.\n",
    "\n",
    "### 3B) Vanilla Logistic Regression Model (Adding Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.714286\n",
       "std       14.526453\n",
       "min        1.000000\n",
       "25%       20.250000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the Age feature and see if we can convert that into multiple Boolean features\n",
    "train['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      34.695294\n",
       "std       52.918912\n",
       "min        0.000000\n",
       "25%        8.050000\n",
       "50%       15.740000\n",
       "75%       33.375000\n",
       "max      512.330000\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the Fare feature and see if we can convert that into multiple Boolean features\n",
    "train['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features for the Age column\n",
    "train['Age_Child']  = np.where((train['Age'] >= 17), 1, 0)\n",
    "train['Age_Adult']  = np.where((train['Age'] <  17) & (train['Age'] < 60), 1, 0)\n",
    "train['Age_Senior'] = np.where((train['Age'] >  60), 1, 0)\n",
    "\n",
    "# Create new features for the Fare column\n",
    "train['Fare_Low']  = np.where((train['Fare'] >= 25), 1, 0)\n",
    "train['Fare_Med']  = np.where((train['Fare'] <  25) & (train['Fare'] < 100), 1, 0)\n",
    "train['Fare_High'] = np.where((train['Fare'] > 100), 1, 0)\n",
    "\n",
    "# Create new features for the Class column\n",
    "train['Class1'] = np.where((train['Class'] == 1), 1, 0)\n",
    "train['Class2'] = np.where((train['Class'] == 2), 1, 0)\n",
    "train['Class3'] = np.where((train['Class'] == 3), 1, 0)\n",
    "\n",
    "# Drop the original columns that we just changed\n",
    "train.drop(['Age', 'Fare', 'Class'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>EmbC</th>\n",
       "      <th>EmbQ</th>\n",
       "      <th>EmbS</th>\n",
       "      <th>Age_Child</th>\n",
       "      <th>Age_Adult</th>\n",
       "      <th>Age_Senior</th>\n",
       "      <th>Fare_Low</th>\n",
       "      <th>Fare_Med</th>\n",
       "      <th>Fare_High</th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Class3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Female  SibSp  Parch  EmbC  EmbQ  EmbS  Age_Child  Age_Adult  \\\n",
       "0         1       0      0      1     1     0     0          0          1   \n",
       "1         1       0      1      1     0     0     1          0          1   \n",
       "2         1       1      2      1     1     0     0          0          1   \n",
       "3         1       1      2      1     1     0     0          0          1   \n",
       "4         1       0      0      2     0     0     1          0          1   \n",
       "\n",
       "   Age_Senior  Fare_Low  Fare_Med  Fare_High  Class1  Class2  Class3  \n",
       "0           0         0         1          0       0       0       1  \n",
       "1           0         0         1          0       0       1       0  \n",
       "2           0         0         1          0       0       0       1  \n",
       "3           0         0         1          0       0       0       1  \n",
       "4           0         1         0          0       0       1       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what the dataset looks like now\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseparate the features from the target feature\n",
    "X = train.drop('Survived', axis = 1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some crossvalidation on our dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Vanilla Logistic Regression on the dataset and see what results we get\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- RESULTS ----------\n",
      "\n",
      "--- R-SQUARED ---\n",
      "0.7966101694915254\n",
      "\n",
      "--- CONFUSION MATRIX ---\n",
      "[[118  25]\n",
      " [ 23  70]]\n",
      "\n",
      "--- PERFORMANCE ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       143\n",
      "           1       0.74      0.75      0.74        93\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       236\n",
      "   macro avg       0.79      0.79      0.79       236\n",
      "weighted avg       0.80      0.80      0.80       236\n",
      "\n",
      "\n",
      "--- INTERCEPTS ---\n",
      "[[ 2.56802163 -0.38739896 -0.21199063  0.47171758 -0.40347073 -0.0968526\n",
      "  -0.99381025  0.9652045  -0.83311923  0.14097059 -0.16957633 -0.05163987\n",
      "   0.90074808  0.04930301 -0.97865683]]\n"
     ]
    }
   ],
   "source": [
    "print('---------- RESULTS ----------')\n",
    "print()\n",
    "print('--- R-SQUARED ---')\n",
    "print(logreg.score(X_test, y_test))\n",
    "print('\\n--- CONFUSION MATRIX ---')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n--- PERFORMANCE ---')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n--- INTERCEPTS ---')\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out the new added features did not make the model any better. It actually was a small amount less accurate.\n",
    "\n",
    "### 3C) Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgereg = RidgeClassifier(alpha = 0.35, fit_intercept = True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "predictions = ridgereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- RESULTS ----------\n",
      "\n",
      "--- R-SQUARED ---\n",
      "0.7966101694915254\n",
      "\n",
      "--- CONFUSION MATRIX ---\n",
      "[[116  27]\n",
      " [ 21  72]]\n",
      "\n",
      "--- PERFORMANCE ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       143\n",
      "           1       0.73      0.77      0.75        93\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       236\n",
      "   macro avg       0.79      0.79      0.79       236\n",
      "weighted avg       0.80      0.80      0.80       236\n",
      "\n",
      "\n",
      "--- INTERCEPTS ---\n",
      "[[ 0.98182309 -0.12473306 -0.07224079  0.15850752 -0.13551862 -0.02298891\n",
      "  -0.33648632  0.33648632 -0.37008322  0.02759927 -0.02759927 -0.07142555\n",
      "   0.34334753  0.00964463 -0.35299216]]\n"
     ]
    }
   ],
   "source": [
    "print('---------- RESULTS ----------')\n",
    "print()\n",
    "print('--- R-SQUARED ---')\n",
    "print(ridgereg.score(X_test, y_test))\n",
    "print('\\n--- CONFUSION MATRIX ---')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n--- PERFORMANCE ---')\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n--- INTERCEPTS ---')\n",
    "print(ridgereg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Ridge regression performs almost exactly as regular Vanilla regression. No strong benefits.\n",
    "\n",
    "### 3D) LASSO Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoreg = Lasso(alpha = 0.005)\n",
    "lassofit = lassoreg.fit(X_train, y_train)\n",
    "predictions = lassofit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- RESULTS ----------\n",
      "\n",
      "--- R-SQUARED ---\n",
      "0.37796512655481385\n",
      "\n",
      "--- INTERCEPTS ---\n",
      "[ 4.68705910e-01 -4.41417384e-02 -1.24007527e-02  7.20251502e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -2.53718104e-01  1.15025668e-15\n",
      " -2.07589537e-02  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  1.49233469e-01  0.00000000e+00 -1.84803585e-01]\n"
     ]
    }
   ],
   "source": [
    "print('---------- RESULTS ----------')\n",
    "print()\n",
    "print('--- R-SQUARED ---')\n",
    "print(lassoreg.score(X_test, y_test))\n",
    "print('\\n--- INTERCEPTS ---')\n",
    "print(lassoreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Results\n",
    "\n",
    "It turns out that the highest-performing model was the simple version of __Vanilla Logistic Regression__ before adding the new features. Additionally, __LASSO Regression__ turned out to perform terribly, most likely due to the fact that there are few "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
