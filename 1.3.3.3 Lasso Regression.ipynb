{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression shrinks parameter estimates, but the estimates never reach exactly 0.  **LASSO** (Least Absolute Shrinkage and Selection Operator), on the other hand, is a model optimization mechanic that works by trying to force small parameter estimates to be equal to zero, effectively dropping them from the model.  This can prevent overfitting, and also works as an embedded feature selection method.  Lasso is extremely handy when you are dealing with thousands or hundreds of thousands of predictors and need to optimize processor time, or when you want to arrive at a simpler solution that is easier to interpret.\n",
    "\n",
    "The cost function to minimize for lasso is _very similar_ to the cost function minimized for ridge. Can you spot the difference?\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-(\\alpha+\\beta x_i))^2+\\lambda\\sum_{j=1}^p|\\beta_j| $$\n",
    "\n",
    "The difference is that rather than penalizing by the sum of *squared* coefficients as ridge does, lasso penalizes by the sum of the *absolute values* of the coefficients.  This means the penalty doesn't increase as swiftly with coefficient size.  Regularization based on the sum of the absolute weights is also called \"**L1 regularization**\".\n",
    "\n",
    "Why would penalizing with the sum of the absolute values of coefficients lead to a solution with zero estimates for some parameters, while penalizing with the sum of the squares of coefficients does not?  It all comes down to derivatives.\n",
    "\n",
    "We encountered derivatives briefly during an earlier assignment on the gradient descent algorithm.  You may recall that a partial derivative represents the sensitivity of one quantity to changes in another quantity.  In the case of both ordinary least squares regression and ridge regression, the derivative used to find the optimal solution is the partial derivative of the cost function relative to the coefficients in $\\beta$:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\beta}$$\n",
    "\n",
    "Unfortunately, that won't work for lasso. While we can calculate a derivative for most of the values of $x$ in lasso, there is no derivative where $x=0$.  You can imagine this as our multi-dimensional surface made up of gradients having a big hole in it (the technical term for the hole is a \"*discontinuity*\"). If the gradient descent algorithm calculates a value that falls in the \"hole\", it has no idea where to go next.  The model \"fails to converge\". In other words, it fails to arrive at an optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Lasso: Coordinate Descent Algorithm\n",
    "\n",
    "Since basing modeling strategy on a surface with a hole in it is obviously not ideal, lasso regression models are optimized using a coordinate descent algorithm rather than a gradient descent algorithm.  Coordinate descent works like this:\n",
    "\n",
    "Pick some starting values for $\\beta$, often $\\beta=0$. \n",
    "\n",
    "For each feature $j$ in $\\beta$:\n",
    "* Predict the outcome using all features except for $j$.  \n",
    "* Look at how the residuals from the model using $\\beta_{-j}$ (all betas except $j$) correlate with feature $j$. This correlation is called $\\rho_j$.  \n",
    "* If the correlation falls within an area enclosing 0 defined by $\\lambda$, set $\\beta_j=0$. (called *soft threshholding*)\n",
    "* If $\\rho_j < \\frac{\\lambda}2$ set $\\beta_j$ equal to $\\rho_j + \\frac{\\lambda}2$\n",
    "* If $\\rho_j > \\frac{\\lambda}2$ set $\\beta_j$ equal to $\\rho_j - \\frac{\\lambda}2$\n",
    "\n",
    "This will iterate through all features 1 through $j$ on each cycle, then begin again.  Alternatively, the algorithm can be set to choose to exclude a feature at random each iteration, rather than cycling through all features.  Each time a feature is checked, it will shrink a bit from the previous time (unless the feature is already set to 0, in which case it will remain 0).\n",
    "\n",
    "Continue until the maximum difference between parameter estimates in the previous cycle and the current cycle is less than a pre-determined threshold $tol$.  For SKlearn, $tol$ defaults to 0.0001.\n",
    "\n",
    "To summarize: Lasso works by iteratively fitting a model to the data while excluding one of the features.  It then checks how well the model reproduces the data, and if the model fit is good enough (with \"good enough\" determined by $\\lambda$) then the excluded feature is deemed unnecessary and its $\\beta$ is set to zero, effectively excluding it from the model. Otherwise, the excluded feature's $\\beta$ is set using a combination of the correlation of the feature with the model residuals ($\\rho_j$) and $\\frac{\\lambda}2$ and a new iteration begins, using the newly-computed $\\beta$ for the previously-excluded feature and excluding a new feature.  This continues until the change in $\\beta$ is less than a pre-determined threshold.\n",
    "\n",
    "Hopefully this demonstrates how lasso can both create overfitting-protection through shrinkage and create sparsity (many parameters set to 0) through feature selection.  Let's see it at work, using the same dataset as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data again. Keep credit card data, drop the index column and any missing data columns\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Default.csv').iloc[:,1:].dropna()\n",
    "\n",
    "# Recode strings to numeric\n",
    "df['default'] = np.where(df['default'] == 'Yes', 1, 0)\n",
    "df['student'] = np.where(df['student'] == 'Yes', 1, 0)\n",
    "names = df.columns\n",
    "df = pd.DataFrame(preprocessing.scale(df), columns = names)\n",
    "\n",
    "# Define the training and test sizes\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "\n",
    "Y_train = df_train['income'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['income'])]\n",
    "\n",
    "# Make new features to capture potential quadratic and cubic reationships bwtween the features\n",
    "df_train['balance_student'] = df_train['balance'] * df_train['student']\n",
    "df_train['balance_default'] = df_train['balance'] * df_train['default']\n",
    "df_train['student_default'] = df_train['student'] * df_train['default']\n",
    "df_train['balance_sqrt']   = (df_train['balance'] + 100) ** 0.5\n",
    "df_train['balance2']       = (df_train['balance'] + 100) ** 2\n",
    "df_train['balance3']       = (df_train['balance'] + 100) ** 3\n",
    "\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['income'])]\n",
    "\n",
    "# Test the simpler model with smaller coefficients\n",
    "Y_test = df_test['income'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n",
    "\n",
    "# Test the more complex model with larger coefficients\n",
    "df_test['balance_student'] = df_test['balance'] * df_test['student']\n",
    "df_test['balance_default'] = df_test['balance'] * df_test['default']\n",
    "df_test['student_default'] = df_test['student'] * df_test['default']\n",
    "df_test['balance_sqrt']   = (df_test['balance'] + 100) ** .5\n",
    "df_test['balance2']       = (df_test['balance'] + 100) ** 2\n",
    "df_test['balance3']       = (df_test['balance'] + 100) ** 3\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² for the model with few features:\n",
      "0.450062579301185\n",
      "\n",
      "Parameter Estimates for the Model with Few Features\n",
      "[-0.         -0.40657726 -0.          0.00114596]\n",
      "\n",
      "\n",
      "R² for the Model with Many Features\n",
      "0.44363376712897096\n",
      "\n",
      "Parameter Estimates for the Model with Many Features\n",
      "[ 0.00000000e+00 -3.89351238e-01  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -2.77688887e-04\n",
      " -7.09158792e-07  3.48711577e+00]\n"
     ]
    }
   ],
   "source": [
    "# Small number of parameters\n",
    "lass = linear_model.Lasso(alpha = 0.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('R² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter Estimates for the Model with Few Features')\n",
    "print(origparams)\n",
    "\n",
    "# Large number of parameters\n",
    "lassBig = linear_model.Lasso(alpha = 0.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\n')\n",
    "print('R² for the Model with Many Features')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter Estimates for the Model with Many Features')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking predictive power using the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44553225151184195\n",
      "\n",
      "0.4380466345914476\n"
     ]
    }
   ],
   "source": [
    "print(lass.score(X_test, Y_test))\n",
    "print()\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization parameter: Lasso\n",
    "\n",
    "The $\\lambda$ for lasso can var between 0 (no penalty, acts like OLS) and infinity.  If $\\lambda$ is too large, all parameters will be set to zero.  \n",
    "\n",
    "Create a plot below of how $R^2$ varies across different values of $\\lambda$ for ridge and lasso regression. Use logic and code similar to the ridge regression demonstration above, and base your plot on the X_train2 feature set.\n",
    "\n",
    "Do lasso and ridge yield the same $R^2$ for a given lambda value?\n",
    "\n",
    "Submit your work and discuss the results with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Lasso and ridge regression are both clear improvements on OLS regression.  Ridge regression is an excellent tool to use with correlated features, while lasso is an efficient method of feature selection when dealing with an unmanageably large feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsquared = pd.DataFrame(columns = [['Lambda', 'R-Squared']])\n",
    "alphas = []\n",
    "rsqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambd in range(1, 10, 2):\n",
    "    lassBig = linear_model.Lasso(alpha=(lambd))\n",
    "    lassBig.fit(X_train2, Y_train)\n",
    "    rsq = lassBig.score(X_train2, Y_train)\n",
    "    alphas.append(lambd)\n",
    "    rsqs.append(rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsquared['Lambda'] = alphas\n",
    "rsquared['R-Squared'] = rsqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Key length (2) exceeds index depth (1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4b3c742f0219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrsquared\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lambda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsquared\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R-Squared'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R-Squared'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3362\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_mi_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m             \u001b[0mnew_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mkeylen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m             raise KeyError('Key length ({0}) exceeds index depth ({1})'\n\u001b[0;32m-> 2248\u001b[0;31m                            ''.format(keylen, self.nlevels))\n\u001b[0m\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeylen\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Key length (2) exceeds index depth (1)'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "varstoplot = list(rsquared.columns)\n",
    "labels = []\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(rsquared['Lambda'], rsquared['R-Squared'])\n",
    "\n",
    "plt.ylabel('R-Squared')\n",
    "plt.xlabel('Lambda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
